# AI 范式五讲之一 -- 基于规则的 (Rule-Based) 范式

## 前言

系列文章主要内容来自于笔者之前报名学习的 NLP 培训班，附加笔者自己的理解与其他参考资料，对于读者的
要求只需要懂基础的 Python 语法即可。

本文乃挖坑 NLP 系列第一篇，基于规则的 NLP 处理方法。 篇中，笔者将介绍如何去根据设定的规则实现简单语句生成。之后，笔者将介绍如何基于规则去实现一个简单的问答系统。

之后的系列文章，相关项目代码与笔记，笔者将会上传到 !(github)[https://github.com/nehcuh/nlp_learning] 上。

## 场景描述

本文主要想要实现两件事情：

1. 构建一个自然语句生成器;
2. 构建一个最简单的对话系统

具体来讲，我们首先希望计算机能够去产生一段话，而且这段话能够符合我们人类对语言的认知。在构建了类似的语句生成器后，我们肯定希望能够将之
应用于具体的实践场景。譬如，现在网络上很多类似的智能客服系统，其最最基本的构建，就是基于自然语句生成器。本文希望通过最简单的 `rule-based`
范式实现一个最简单的 “傻瓜” 对话系统，并在之后的系列文章中，对这样的对话系统进行进一步地构建与升级。

## 简单的语句范式

下面的 `simple_grammar` 就定义了一个简单的语言范式，譬如， `sentence => noun_phrase verb_phrase` 就定义了一个语句 (`sentence`)
的组成是怎么样的，即名词短语加动词短语 (`noun_phrase verb_phrase`), 之后，分别对名词短语 (`noun_phrase`), 动词短语 (`verb_phrase`)
进行了分解。 当类似的 `rule` 被制定后，程序就可以基于这样的 `rule`, 通过类似递归与随机选择，自动生成相应的语句。

```python
simple_grammar = """
   sentence => noun_phrase verb_phrase
   noun_phrase => Article Adj* noun
   Adj* => null | Adj Adj*
   verb_phrase => verb noun_phrase
   Article => 一个 | 这个
   noun => 女人 | 篮球 | 桌子 | 小猫
   verb => 看着 | 坐在 | 听着 | 看见
   Adj => 蓝色的 | 好看的 | 小小的
   """
```

如何针对上述范式进行分解，并基于此，去产生语句，笔者简单归纳为以下两个步骤。

### 1. 范式分解

其实在生成规则的时候，我们已经对一句话的结构进行了拆解，譬如，一句话至少应该包括主语和谓语，
主语可以使 `noun_phrase`, 谓语可以是 `verb_phrase`； 对于主语短语，又可以继续分解为介词，
形容词 [可选] 和名词，即 `noun_phrase => Article Adj* noun`；之后，对于介词 (`Article`),
形容词 (`Adj*`) 和名词 (`noun`) 又可以继续分解，一直分解到最小单位。

但是这里我们会遇到一个问题，如何让程序去理解这样的结构？这里又牵涉到数据结构的知识，当然，这里
的问题还不至于那么复杂。利用 `dict` 去表述这样的语法结构应该就足够了。读者们可以用 “树”
这样的结构去理解语法结构。

!(句型结构)[rule_based_01.svg]

如上图所示，对应最小的无法再分的结点，我们将之理解为叶结点，能够有下一层结构的结点，我们称之为支结点，我们将分支结点作为 `dict` 的 `key`, 对其下一层结构用 `list` 表示。之后，当我们想要知道某个支结点的下层结构的时候，只需要使用递归的方式，如果没有叶结点就不断往下查找，就可以实现对相应语法树的分解。譬如 `noun_phrase` (名词短语)
我们可以将之表示为 `{'noun_phrase': ['Article', 'Adj*', 'noun']}`, 然后对于 `noun_phrase`
的相应分支进行近一步分解，譬如 `Article` 可以表示为 `{'Article': ['一个', '这个']}`, 而 `一个`, `这个` 显然已经无法进行进一步分解，类似地，对 `Adj*`, `noun` 采取一样的方式进行分解，最后将所有分解
结果组合起来，就可以得到我们基于规则 (树结构) 的语句。

下面的代码就是将原始规则转换为相应数据结构的代码，

```python
def create_grammar(gram: str, outer_delimiter: str="=>", inner_delimiter: str="|", line_delimiter: str="\n"):
    """
    对 gram 进行分解，分为两层 dict
    :param gram: 语法规则
    :param outer_delimiter: 外层语法分隔符
    :param inner_delimiter: 内层语法分隔符
    :param line_delimiter: 换句分隔符
    """
    grammar = {}
    for line in gram.split(line_delimiter):
        if not line.strip(): # 非空行
            continue
        exp, stmt = line.split(outer_delimiter)
        grammar[exp.split()[0]] = [s.split() for s in stmt.split(inner_delimiter)]
    return grammar
```

通过调用 `create_grammar`, 就有了相应的语法结构

```python
gram = create_grammar(simple_grammar)
print(gram)
```

输出为

```
{'sentence': [['noun_phrase', 'verb_phrase']],
 'noun_phrase': [['Article', 'Adj*', 'noun']],
 'Adj*': [['null'], ['Adj', 'Adj*']],
 'verb_phrase': [['verb', 'noun_phrase']],
 'Article': [['一个'], ['这个']],
 'noun': [['女人'], ['篮球'], ['桌子'], ['小猫']],
 'verb': [['看着'], ['坐在'], ['听着'], ['看见']],
 'Adj': [['蓝色的'], ['好看的'], ['小小的']]}
```

### 2. 递归生成

如上所示，通过递归的方式，可以实现对语法数的搜索，实际上，通过树最顶层进行递归，只要是不是叶结点，我们就进行递归查找，最终我们总是能得到基于规则的语句。

```python
import random
def generate(gram: dict, target: str):
    """
    根据 target 对 gram 进行查找分解
    """
    if target not in gram: return target
    expand = [generate(gram, t) for t in random.choice(gram[target])]
    return ''.join([e if e != '/n' else '\n' for e in expand if e != 'null'])
```

如果对函数输入 `target` 为 `sentence` 就可以生成相应的语句，

```python
generate(gram, 'sentence')
```

输出为 (结果由于选择的随机性，可能会呈现不同的结果)

```
'一个好看的女人看着这个桌子'
```

## “傻瓜” 对话系统 -- 西部世界机器人

在完成了自然语句的生成后，我们是不是可以去更近一步，去让计算机与我们进行交互，譬如一个简单的对话系统。之前网络上有部很火的 “西部世界”，电视剧
里的仿生机器人，说话就与我们人类无异，而且能够与人类进行交谈。这里，就简单实用 `rule-based` 方式，试图实现一个最简单的西部世界机器人的对话
系统。

### 1. `Rule` 制定

首先，明确一个最简单的对话系统的主体，至少需要两个主体，即，**问话者**，这里指 “人类”，这里用 `human` 表示； **回答者**，这里指
“机器人”，用 `host` 表示。

对于 `human` 而言，他的问话会是什么样子？仿照之前人类语句生成的范式，我们可以定义一个 `human` 的
语句结构，譬如，如下范式

```python
human = """
human => 自己 寻找 活动
自己 => 我 | 俺 | 我们
寻找 => 看看 | 找找 | 想找点
活动 => 乐子 | 玩的
"""
```

对于机器人而言，她的回答是什么样子，其实从我们日常生活中遇到的机构服务人员的说话方式可以很自然地想到
类似如下的范式

```python
host = """
host => 寒暄 报数 询问 业务相关 结尾
报数 => 我是 数字 号 ，
数字 => 单个数字 | 数字 单个数字
单个数字 => 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9
寒暄 => 称谓 打招呼 | 打招呼
称谓 => 人称 ，
人称 => 先生 | 女士 | 小朋友
打招呼 => 你好， | 您好，
询问 => 请问您要 | 您需要
业务相关 => 玩玩 具体业务
具体业务 => 喝酒 | 打牌 | 打猎 | 赌博
结尾 => 吗？
"""
```

### 2. 范式分解

直接使用之前定义的 `create_grammar` 函数就可以生成相应的语法结构

```python
human_gram = create_grammar(human)
host_gram = create_grammar(host)
print(human_gram)
print(host_gram)
```

输出为

```
{'human': [['自己', '寻找', '活动']],
 '自己': [['我'], ['俺'], ['我们']],
 '寻找': [['看看'], ['找找'], ['想找点']],
 '活动': [['乐子'], ['玩的']]}
{'host': [['寒暄', '报数', '询问', '业务相关', '结尾']],
 '报数': [['我是', '数字', '号', '，']],
 '数字': [['单个数字'], ['数字', '单个数字']],
 '单个数字': [['1'], ['2'], ['3'], ['4'], ['5'], ['6'], ['7'], ['8'], ['9']],
 '寒暄': [['称谓', '打招呼'], ['打招呼']],
 '称谓': [['人称', '，']],
 '人称': [['先生'], ['女士'], ['小朋友']],
 '打招呼': [['你好，'], ['您好，']],
 '询问': [['请问您要'], ['您需要']],
 '业务相关': [['玩玩', '具体业务']],
 '具体业务': [['喝酒'], ['打牌'], ['打猎'], ['赌博']],
 '结尾': [['吗？']]}
```

### 3. 递归生成

```python
generate(host_gram, target="host")
```

相应输出为

```
'女士，你好，我是83号，您需要玩玩赌博吗？'
```

## 后篇：语言评价

实际上，一个简单的 rule-based 系统已经能够实现包括语句生成，自动问答的功能，但是，我们可以看到，类似的系统的问答，基本上都是在我们制定的范围内，
而且对于生成的语句，哪怕我们已经指定了规则，依然千奇百怪。

于是，一个很现实的问题就出现了，如何去评价类似的问答系统的语句好坏，然后针对其进行改进。这些是我们下一篇 `Probability-based` 范式准备去介绍
和讲解的。

## 结语

之前与同事聊天，我们讨论到一个挺怪的现象， `youtube` 这样的网站上非常多的学习视频，但是往往都是印度人，
美国人去分享，哪怕到了国内的 `bilibili`, `腾讯视频` 等，不说分享学习的视频很少的现象，哪怕是分享的学习视频，往往也是从墙外搬运过来的。在现代社会里，一切往钱看，往结果看，固然是一种选择，不过，对自我价值的实现，对社会的贡献而言，我们是不是能够去 “人过留名，雁过留声” 呢？

笔者写了一系列文章，内容而言，其实笔者也不算满意，但是刚刚分享两篇心得，就会有人回复说，笔者这样做不对，干嘛要把知识经验分享出来，这样子还怎么赚钱？其实知识一直都在那里，只看你有没有心去学习和进步。技术是
在分享和交流中不断进步的，敝帚自珍其实容易陷入沾沾自喜的狂妄中，不断向优秀的人学习，对自我进行总结，才是自我成长的不二之道。

最后，不管笔者写的好与坏，至少，笔者自认为，每一篇的内容，都包含了笔者的见解与思考，也希望读者们能够有所收获。
